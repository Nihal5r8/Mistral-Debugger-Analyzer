# utils/visualizer.py
import streamlit.components.v1 as components
import re
from collections import OrderedDict

# ---------- Helpers ----------
def _safe_id(label, used):
    """Make a safe ID from label, ensuring uniqueness."""
    base = re.sub(r'[^A-Za-z0-9_]', '_', label).strip('_')
    if not base:
        base = "node"
    if re.match(r'^\d', base):
        base = "n_" + base
    candidate = base
    i = 1
    while candidate in used:
        candidate = f"{base}_{i}"
        i += 1
    used.add(candidate)
    return candidate

def _clean_label(lbl):
    """Normalize label for display inside quotes."""
    if lbl is None:
        return ""
    s = str(lbl)
    s = s.replace('\r', ' ').replace('\n', ' ')
    s = s.replace('"', "'")
    s = re.sub(r'\s+', ' ', s).strip()
    return s

def _extract_label_from_token(token):
    """
    Try to extract a human-friendly label from a token.
    Prefer content inside [] or () or quotes; otherwise fallback to token trimmed.
    """
    token = token.strip()
    # Try bracket [] first
    m = re.search(r'\[([^\]]+)\]', token)
    if m:
        return _clean_label(m.group(1))
    # Try parentheses ()
    m = re.search(r'\(([^\)]+)\)', token)
    if m:
        return _clean_label(m.group(1))
    # Try quoted strings
    m = re.search(r'"([^"]+)"', token)
    if m:
        return _clean_label(m.group(1))
    m = re.search(r"'([^']+)'", token)
    if m:
        return _clean_label(m.group(1))
    # If token contains '-' trailing like 'DFS -' remove trailing dashes and words
    token = re.sub(r'\s*-\s*$', '', token)
    # remove stray remnants like repeated IDs: take first few words if long
    token = _clean_label(token)
    if len(token) > 60:
        token = token[:57] + '...'
    return token if token else "node"

# ---------- Main sanitizer ----------
def validate_and_fix_mermaid(src: str) -> str:
    """
    Robust sanitizer for messy LLM-generated Mermaid.
    Strategy:
    - Remove code fences and 'mermaid version' garbage.
    - Strip any previously auto-generated declarations (we will rebuild).
    - Collapse newlines to spaces to repair labels split across lines.
    - Split by '-->' to get token sequence and reconstruct edges individually.
    - Build safe IDs, declare nodes once, deduplicate edges.
    - Return a clean 'flowchart TD' block.
    """
    if not src:
        return ""

    s = str(src)

    # Remove common noise
    s = s.replace("```mermaid", "").replace("```", "")
    s = re.sub(r'mermaid\s+version\s+[0-9\.]+', '', s, flags=re.IGNORECASE)
    # Remove prior autogenerated id declarations like Some__Id[...] (they confuse the parser)
    s = re.sub(r'^[A-Za-z0-9_]+__.*\[".*"\]\s*$', '', s, flags=re.MULTILINE)

    # Remove explicit 'flowchart TD' or 'graph' occurrences temporarily (we'll add a clean one)
    s = re.sub(r'(?i)^\s*flowchart\s+(TD|LR|RL|BT|TB)\s*', '', s, flags=re.MULTILINE)
    s = re.sub(r'(?i)^\s*graph\s+(TD|LR|RL|BT|TB)\s*', '', s, flags=re.MULTILINE)

    # Remove stray 'subgraph NAME' tokens for now (LLM often emits broken subgraphs)
    s = re.sub(r'(?i)subgraph\s+[A-Za-z0-9_\-]+\s*', '', s)
    # Remove stray 'end' tokens that are likely unmatched
    s = re.sub(r'(?m)^\s*end\s*$', '', s)

    # Collapse multiple whitespace and newlines into single spaces,
    # but preserve explicit arrow tokens '-->' (we'll split by them)
    # First, ensure arrow tokens are normalized
    s = s.replace('->', '-->')
    s = re.sub(r'\s*-->\s*', ' --> ', s)

    # Join broken label lines: collapse all newlines to spaces (this is intentional and safe here)
    body = ' '.join(line.strip() for line in s.splitlines() if line.strip())
    body = re.sub(r'\s+', ' ', body).strip()

    if not body:
        return "flowchart TD\n"

    # Now split on ' --> ' to get a sequence of tokens (some tokens may be standalone nodes)
    parts = [p.strip() for p in re.split(r'\s*-->\s*', body) if p.strip()]

    # If no parts, return header only
    if not parts:
        return "flowchart TD\n"

    used_ids = set()
    id_map = OrderedDict()  # label -> id (preserve insertion order)
    edges = []
    nodes_order = []  # list of (id,label) in order of first appearance

    # Clean tokens: tokens may contain text like 'DFS([DFS function]) DFS -' etc.
    # We'll extract a readable label for each token and assign a safe id.
    cleaned_tokens = []
    for token in parts:
        # Remove trailing arrows remnants or stray punctuation
        token = token.strip()
        token = re.sub(r'\s*-\s*$', '', token)
        token = re.sub(r'^\s*-\s*', '', token)
        # If token includes duplicate 'DFS [..] DFS -' sequences, try to keep only the first bracketed segment
        # Prefer bracketed [] or parentheses () content — extract label
        label = _extract_label_from_token(token)
        if not label:
            # fallback: use first 6-8 words
            label = ' '.join(token.split()[:6])
        cleaned_tokens.append((token, label))

    # Build edges between consecutive cleaned tokens
    prev_id = None
    for raw, label in cleaned_tokens:
        # Map label to id (deduplicating identical labels)
        key = label
        if key in id_map:
            nid = id_map[key]
        else:
            nid = _safe_id(key, used_ids)
            id_map[key] = nid
            nodes_order.append((nid, key))
        if prev_id is not None:
            # add edge prev_id --> nid
            edges.append((prev_id, nid))
        prev_id = nid

    # Additionally, if original body had explicit node declarations like 'Node["Label"]'
    # we ignore them (we rebuilt nodes). This avoids duplicate weird IDs.

    # Deduplicate edges preserving order
    seen_edges = set()
    dedup_edges = []
    for a, b in edges:
        if (a, b) not in seen_edges:
            dedup_edges.append((a, b))
            seen_edges.add((a, b))

    # Construct final mermaid lines
    lines = ["flowchart TD"]
    # node declarations (in order)
    for nid, label in nodes_order:
        lines.append(f'{nid}["{_clean_label(label)}"]')
    # edges
    for a, b in dedup_edges:
        lines.append(f'{a} --> {b}')

    cleaned = "\n".join(lines)
    return cleaned

# ---------- Renderer ----------
def render_mermaid(mermaid_code: str):
    """
    Render the cleaned/transformed Mermaid in an HTML card using mermaid.esm.
    Shows the cleaned source below for debugging.
    """
    fixed = validate_and_fix_mermaid(mermaid_code)

    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
      <script type="module">
        import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs";
        mermaid.initialize({{ startOnLoad: true, securityLevel: 'loose', theme: 'default', flowchart: {{ useMaxWidth: true }} }});
      </script>
      <style>
        body {{ margin:0; font-family: Inter, Arial, sans-serif; background: transparent; }}
        .card {{ background:#ffffff; border-radius:12px; padding:16px; box-shadow:0 8px 30px rgba(0,0,0,0.08); max-width:100%; }}
        .mermaid {{ overflow:auto; min-height:220px; }}
        pre.fixed {{ background:#f6f8fb; padding:10px; border-radius:8px; overflow:auto; margin-top:10px; font-size:13px; }}
        .err {{ display:none; color:#b71c1c; background:#ffebee; padding:10px; border-left:4px solid #b71c1c; border-radius:6px; margin-bottom:10px; }}
      </style>
    </head>
    <body>
      <div class="card">
        <div class="err" id="err">⚠️ Mermaid parsing may have failed — fixed source shown below for debugging.</div>
        <div class="mermaid">
{fixed}
        </div>
        
      </div>
      <script>
        window.addEventListener('load', () => {{
          setTimeout(() => {{
            const m = document.querySelector('.mermaid');
            if (m && !m.getAttribute('data-processed')) {{
              document.getElementById('err').style.display = 'block';
            }}
          }}, 1000);
        }});
      </script>
    </body>
    </html>
    """
    components.html(html, height=650, scrolling=True)
